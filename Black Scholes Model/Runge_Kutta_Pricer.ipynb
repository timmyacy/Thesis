{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-02T19:57:41.915207Z",
     "start_time": "2025-09-02T19:57:41.445189Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from math import erf, exp, log, sqrt\n",
    "\n",
    "\n",
    "def N(x: float) -> float:\n",
    "    \"\"\"\n",
    "    This function computes the cumulative distribution function (CDF) for the standard normal distribution, N(x).\n",
    "    :param x: The value to evaluate the CDF at\n",
    "    :return: The cumulative probability up to x\n",
    "    \"\"\"\n",
    "    return 0.5 * (1.0 + erf(x / sqrt(2.0)))\n",
    "\n",
    "def bs_price_call(S0: float, K: float, r:float, sigma: float, T: float) -> float:\n",
    "    \"\"\"\n",
    "    This calculates the analytical price of a European call option using the Black-Scholes formula.\n",
    "\n",
    "    :param S0: Current asset price\n",
    "    :param K: Option strike price\n",
    "    :param r: Risk-free interest rate\n",
    "    :param sigma: Volatility of the asset\n",
    "    :param T: Time to maturity in years\n",
    "    :return: The price of the European call option\n",
    "    \"\"\"\n",
    "\n",
    "    # Fix NPE where time to maturity or volatility are zero.\n",
    "    if T <= 0 or sigma <= 0:\n",
    "        return max(S0 - K, 0.0) * exp(-r * T)\n",
    "\n",
    "    # Standard Black-Scholes formula parameters\n",
    "    vol = sigma * sqrt(T)\n",
    "    d1 = (log(S0 / K) + (r + 0.5 * sigma**2) * T) / vol\n",
    "    d2 = d1 - vol\n",
    "\n",
    "    # Return the analytical price\n",
    "    return S0 * N(d1) - K * exp(-r * T) * N(d2)\n",
    "\n",
    "def payoff_call(S_t, K):\n",
    "    \"\"\"\n",
    "    Calculates the final payoff of a European call option\n",
    "\n",
    "    :param S_t: The simulated asset prices at maturity\n",
    "    :param K: The strike price\n",
    "    :return: Array of payoff for each path being simulated\n",
    "    \"\"\"\n",
    "\n",
    "    return np.maximum(S_t - K, 0.0)\n",
    "\n",
    "\n",
    "def rk_step(s, dW, dt, r, sigma):\n",
    "    \"\"\"\n",
    "    Performs a single rk time step.\n",
    "\n",
    "    :param s: Array of current asset prices\n",
    "    :param dW: Array of Wiener increments for the step\n",
    "    :param dt: The time step size\n",
    "    :param r: Risk-free rate\n",
    "    :param sigma: Volatility\n",
    "    :return: Asset price at the next time step\n",
    "    \"\"\"\n",
    "     # Predictor step (Euler-Maruyama guess)\n",
    "    Y = s + r * s *dt + sigma * s *dW + 0.5 * (sigma**2) *s* (dW**2 - dt)\n",
    "    # Corrector step (using the predictor Y to refine the solution)\n",
    "    return (s + 0.5 * (r * s + r * Y) * dt          # Trapezoidal approximation of the drift\n",
    "            + sigma * s * dW                      # Diffusion term\n",
    "            + 0.5 * (sigma**2) * s * (dW**2 - dt))  # rk correction term\n",
    "\n",
    "\n",
    "\n",
    "def rk_step_to_maturity(S0: float, dW: np.ndarray, dt: float, r: float, sigma: float):\n",
    "    \"\"\"\n",
    "    Simulates multiple asset price paths from t=0 to maturity (T) by using the function above.\n",
    "\n",
    "    :param S0: Initial asset price\n",
    "    :param dW: A 2D array of Wiener increments for all paths and steps.\n",
    "    :param dt: The time step size\n",
    "    :param r: Risk-free rate\n",
    "    :param sigma: Volatility\n",
    "    :return: The final asset price for each path at maturity\n",
    "    \"\"\"\n",
    "    # Initializes all paths to the starting price S0\n",
    "    s = np.full(dW.shape[0], S0, dtype=float)\n",
    "\n",
    "    # Loop over each time step\n",
    "    for j in range(dW.shape[1]):\n",
    "        s = rk_step(s, dW[:, j], dt, r, sigma)\n",
    "\n",
    "    # Final check to avoid error, non-negative values\n",
    "    return np.maximum(s, 0.0)\n",
    "\n",
    "def mlmc_sample_level_rk(S0, K, r, sigma, T, l, N_l, rng, M=2):\n",
    "    \"\"\"\n",
    "    Generates samples for a single level 'l' of the MLMC simulation\n",
    "\n",
    "    :param S0: Initial asset price\n",
    "    :param K: Option strike price\n",
    "    :param r: Risk-free rate\n",
    "    :param sigma: Volatility\n",
    "    :param T: Time to maturity in years\n",
    "    :param l: The current MLMC level where 0 is the coarsest\n",
    "    :param N_l: Number of paths to simulate for this level\n",
    "    :param rng: Random number generator\n",
    "    :param M: Refinement factor between levels\n",
    "    :return: A tuple containing:\n",
    "            - Y : The array of sample values for this level.\n",
    "            - cost: The computational cost per sample at this level.\n",
    "    \"\"\"\n",
    "\n",
    "    n_fine = M**l\n",
    "    dt_f = T / n_fine\n",
    "    cost = n_fine\n",
    "\n",
    "    # Generate a set of fine Wiener increments\n",
    "    dW_f = rng.normal(0.0, sqrt(dt_f), size=(N_l, n_fine))\n",
    "\n",
    "    # The coarsest level (l=0) is a standard Monte Carlo simulation.\n",
    "    if l == 0:\n",
    "        Sf = rk_step_to_maturity(S0, dW_f, dt_f, r, sigma)\n",
    "        Y = exp(-r * T) * payoff_call(Sf, K)\n",
    "    else:\n",
    "        # For all other levels, we calculate the difference create a coarse path\n",
    "        # by summing adjacent fine Wiener increments.\n",
    "        dW_c = dW_f.reshape(N_l, n_fine // M, M).sum(axis=2)\n",
    "\n",
    "        # Simulate both fine and coarse paths.\n",
    "        Sf = rk_step_to_maturity(S0, dW_f, dt_f, r, sigma)\n",
    "        Sc = rk_step_to_maturity(S0, dW_c, 2 * dt_f, r, sigma)\n",
    "\n",
    "        # The sample is the difference of the discounted payoffs.\n",
    "        Y = exp(-r * T) * (payoff_call(Sf, K) - payoff_call(Sc, K))\n",
    "\n",
    "    return Y, cost\n",
    "\n",
    "def mlmc_adaptive_rk(S0, K, r, sigma, T, eps=0.01, M=2, N0=1000, L_min=2, L_max=8, seed=42):\n",
    "    \"\"\"\n",
    "    This implements an adaptive algorithm that automatically determines the\n",
    "    number of levels and samples needed to achieve a target accuracy.\n",
    "\n",
    "    :param S0: Initial asset price\n",
    "    :param K: Option strike price\n",
    "    :param r: Risk-free rate\n",
    "    :param sigma: Volatility\n",
    "    :param T: Time to maturity in years\n",
    "    :param eps: The desired standard error of the final estimate\n",
    "    :param M: The refinement factor between levels\n",
    "    :param N0: Initial number of samples for each level\n",
    "    :param L_min: Minimum number of levels to be simulated\n",
    "    :param L_max: Maximum number of levels to be simulat\n",
    "    :param seed: Random number generator\n",
    "    :return:The final price estimate, its standard error etc\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Initialize arrays to store means, variances, and sample counts for each level.\n",
    "    L = L_min\n",
    "    means = np.zeros(L_max + 1)\n",
    "    vars = np.zeros(L_max + 1)\n",
    "    Nl = np.zeros(L_max + 1, dtype=int)\n",
    "    costs = np.zeros(L_max + 1)\n",
    "\n",
    "    # Initial sampling for the first few levels\n",
    "    for l in range(L + 1):\n",
    "        Nl[l] = max(100, N0 // (M ** l))\n",
    "        Y, cost_per_sample = mlmc_sample_level_rk(S0, K, r, sigma, T, l, Nl[l], rng, M)\n",
    "        means[l] = np.mean(Y)\n",
    "        vars[l] = np.var(Y, ddof=1)\n",
    "        costs[l] = cost_per_sample\n",
    "        print(f\"Level {l}: N={Nl[l]}, mean={means[l]:+.4e}, var={vars[l]:.2e}\")\n",
    "\n",
    "    # Adaptive loop\n",
    "    for iteration in range(15):\n",
    "        # Check if we need more levels, add finer levels if we do\n",
    "        if L < L_max and abs(means[L]) > eps / sqrt(2):\n",
    "            L += 1\n",
    "            Nl[L] = max(100, N0 // (M ** L))\n",
    "            Y, cost_per_sample = mlmc_sample_level_rk(S0, K, r, sigma, T, L, Nl[L], rng, M)\n",
    "            means[L] = np.mean(Y)\n",
    "            vars[L] = np.var(Y, ddof=1)\n",
    "            costs[L] = cost_per_sample\n",
    "            print(f\"Added level {L}: N={Nl[L]}, mean={means[L]:+.4e}, var={vars[L]:.2e}\")\n",
    "            continue\n",
    "\n",
    "        # Check if the desired accuracy (epsilon) has been met\n",
    "        total_var = sum(vars[l] / max(Nl[l], 1) for l in range(L + 1))\n",
    "        if total_var < eps**2:\n",
    "            print(f\"Converged: total variance {total_var:.3e} < target {eps**2:.3e}\")\n",
    "            break\n",
    "\n",
    "        # Calculate optimal samples using Giles' formula,minimise cost for given variane\n",
    "        N_opt = np.zeros(L + 1)\n",
    "        for l in range(L + 1):\n",
    "            if vars[l] > 0 and costs[l] > 0:\n",
    "                N_opt[l] = max(100, int(np.sqrt(vars[l] / costs[l]) *\n",
    "                                 sum(np.sqrt(vars[:L+1] * costs[:L+1])) / eps**2))\n",
    "\n",
    "        # Run additional samples if variance is high and cost is low\n",
    "        samples_added = 0\n",
    "        for l in range(L + 1):\n",
    "            extra = max(0, int(N_opt[l] - Nl[l]))\n",
    "            # Generate new samples\n",
    "            if extra > 0:\n",
    "                Y_extra, _ = mlmc_sample_level_rk(S0, K, r, sigma, T, l, extra, rng, M)\n",
    "\n",
    "                # Update mean and variance with the new samples\n",
    "                if Nl[l] == 0:\n",
    "                    means[l] = np.mean(Y_extra)\n",
    "                    vars[l] = np.var(Y_extra, ddof=1) if extra > 1 else 0.0\n",
    "                else:\n",
    "                    total_samples = Nl[l] + extra\n",
    "                    combined_mean = (Nl[l] * means[l] + np.sum(Y_extra)) / total_samples\n",
    "\n",
    "                    if extra > 1:\n",
    "                        var_extra = np.var(Y_extra, ddof=1)\n",
    "                        vars[l] = ((Nl[l] - 1) * vars[l] + (extra - 1) * var_extra +\n",
    "                                  Nl[l] * (means[l] - combined_mean)**2 +\n",
    "                                  extra * (np.mean(Y_extra) - combined_mean)**2) / (total_samples - 1)\n",
    "                    means[l] = combined_mean\n",
    "\n",
    "                Nl[l] += extra\n",
    "                samples_added += extra\n",
    "                print(f\"Level {l}: added {extra} samples, new N={Nl[l]}, mean={means[l]:+.4e}\")\n",
    "\n",
    "        if samples_added == 0:\n",
    "            print(\"No additional samples needed - convergence achieved\")\n",
    "            break\n",
    "\n",
    "    # Sum mean from all level to get final estimate\n",
    "    price = sum(means[:L+1])\n",
    "    se = sqrt(sum(vars[l] / max(Nl[l], 1) for l in range(L + 1)))\n",
    "    total_cost = sum(Nl[l] * costs[l] for l in range(L + 1))\n",
    "\n",
    "    print(f\"\\n===  rk Scheme Results ===\")\n",
    "    print(f\"Final levels: L={L}\")\n",
    "    print(f\"Price: {price:.6f} ± {se:.6f}\")\n",
    "    print(f\"Total computational cost: {total_cost:.0f}\")\n",
    "    print(f\"Samples per level: {Nl[:L+1]}\")\n",
    "\n",
    "    return price, se, L, Nl[:L+1], vars[:L+1], total_cost\n",
    "\n",
    "\n",
    "def weak_order_convergence_rk(S0, K, r, sigma, T, Lmax=64, Npaths=1000000, seed=332093):\n",
    "    \"\"\"\n",
    "    Performs a weak order convergence analysis for the rk scheme,bias vs time step size on log-log scale\n",
    "    Slope is the weak convergence\n",
    "\n",
    "    :param S0: Initial asset price\n",
    "    :param K: Option strike price\n",
    "    :param r: Risk-free rate\n",
    "    :param sigma: Volatility\n",
    "    :param T: Time to maturity in years\n",
    "    :param Lmax: Maximum number of levels to be simulated\n",
    "    :param Npaths: Number of paths to simulate\n",
    "    :param seed: Random number generator\n",
    "    :return: Result and weak order\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    disc = exp(-r * T)\n",
    "    exact_price = bs_price_call(S0, K, r, sigma, T)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Test range of time step\n",
    "    steps_list = [1, 2, 4, 8, 16, 32, 64]\n",
    "    steps_list = [n for n in steps_list if n <= Lmax]\n",
    "\n",
    "    print(\"===  rk Weak Order Convergence ===\")\n",
    "\n",
    "    for n in steps_list:\n",
    "        dt = T / n\n",
    "        # Generate fresh Brownian paths for each resolution\n",
    "        dW = rng.normal(0.0, sqrt(dt), size=(Npaths, n))\n",
    "        S_approx = rk_step_to_maturity(S0, dW, dt, r, sigma)\n",
    "        P_approx = disc * np.maximum(S_approx - K, 0.0)\n",
    "\n",
    "        # Calculate the bias\n",
    "        mean_approx = np.mean(P_approx)\n",
    "        bias = mean_approx - exact_price\n",
    "        abs_bias = abs(bias)\n",
    "\n",
    "        # Standard error of the mean\n",
    "        se_mean = np.std(P_approx, ddof=1) / np.sqrt(Npaths)\n",
    "\n",
    "        results.append((n, dt, bias, abs_bias, se_mean))\n",
    "        print(f\"Steps: {n:3d}, dt: {dt:.6f}, bias: {bias:+.3e}, abs_bias: {abs_bias:.3e} ± {se_mean:.3e}\")\n",
    "\n",
    "    # Fit convergence rate - use abs bias values\n",
    "    dts = np.array([r[1] for r in results])\n",
    "    abs_biases = np.array([r[3] for r in results])\n",
    "    se_biases = np.array([r[4] for r in results])\n",
    "\n",
    "    # Use points where bias is statistically significant\n",
    "    mask = abs_biases > 2.0 * se_biases\n",
    "    if np.sum(mask) >= 2:\n",
    "        use_dts, use_biases = dts[mask], abs_biases[mask]\n",
    "        log_dts = np.log(use_dts)\n",
    "\n",
    "        log_biases = np.log(use_biases)\n",
    "        alpha, _ = np.polyfit(log_dts, log_biases, 1)\n",
    "        weak_order = alpha\n",
    "        print(f\"rk weak order estimate: {weak_order:.3f}\")\n",
    "    else:\n",
    "        # This is a fall back for when the time steps (dt) are too small,else program breaks\n",
    "        weak_order = 1.0\n",
    "        print(\"Using theoretical weak order = 1.0\")\n",
    "    return results, weak_order\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    S0, K, r, sigma, T = 100.0, 100.0, 0.05, 0.20, 1.0\n",
    "    exact_price = bs_price_call(S0, K, r, sigma, T)\n",
    "    print(f\"\\nBlack–Scholes call price: {exact_price:.6f}\\n\")\n",
    "\n",
    "    # Run adaptive MLMC for  RK scheme\n",
    "    print(\"=== Adaptive MLMC for  SRK Scheme ===\")\n",
    "    price, se, L, Nl, var, cost = mlmc_adaptive_rk(S0, K, r, sigma, T, eps=0.01, L_max=8, N0=2000, seed=42221)\n",
    "\n",
    "    # Weak order analysis\n",
    "    print(\"\\n\")\n",
    "    weak_results, weak_order = weak_order_convergence_rk(S0, K, r, sigma, T, Lmax=64, Npaths=100000, seed=21541254)\n",
    "\n",
    "    print(f\"\\nFinal rk weak order estimate: {weak_order:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black–Scholes call price: 10.450584\n",
      "\n",
      "=== Adaptive MLMC for  rk Scheme ===\n",
      "Level 0: N=2000, mean=+9.9455e+00, var=1.93e+02\n",
      "Level 1: N=1000, mean=+6.8421e-02, var=7.46e-02\n",
      "Level 2: N=500, mean=+3.6417e-02, var=1.81e-02\n",
      "Added level 3: N=250, mean=+2.8607e-02, var=6.60e-03\n",
      "Added level 4: N=125, mean=+1.4883e-02, var=1.55e-03\n",
      "Added level 5: N=100, mean=+6.6809e-03, var=2.59e-04\n",
      "Level 0: added 2085385 samples, new N=2087385, mean=+1.0314e+01\n",
      "Level 1: added 28019 samples, new N=29019, mean=+6.3195e-02\n",
      "Level 2: added 9619 samples, new N=10119, mean=+3.5862e-02\n",
      "Level 3: added 4067 samples, new N=4317, mean=+2.2422e-02\n",
      "Level 4: added 1352 samples, new N=1477, mean=+1.1474e-02\n",
      "Level 5: added 327 samples, new N=427, mean=+4.9404e-03\n",
      "Level 0: added 134346 samples, new N=2221731, mean=+1.0315e+01\n",
      "Level 1: added 2111 samples, new N=31130, mean=+6.3393e-02\n",
      "Level 4: added 46 samples, new N=1523, mean=+1.1447e-02\n",
      "Level 5: added 8 samples, new N=435, mean=+4.8438e-03\n",
      "Converged: total variance 9.981e-05 < target 1.000e-04\n",
      "\n",
      "===  rk Scheme Results ===\n",
      "Final levels: L=5\n",
      "Price: 10.453002 ± 0.009991\n",
      "Total computational cost: 2397291\n",
      "Samples per level: [2221731   31130   10119    4317    1523     435]\n",
      "\n",
      "\n",
      "===  rk Weak Order Convergence ===\n",
      "Steps:   1, dt: 1.000000, bias: -1.455e-01, abs_bias: 1.455e-01 ± 4.535e-02\n",
      "Steps:   2, dt: 0.500000, bias: -9.647e-02, abs_bias: 9.647e-02 ± 4.599e-02\n",
      "Steps:   4, dt: 0.250000, bias: -2.400e-02, abs_bias: 2.400e-02 ± 4.631e-02\n",
      "Steps:   8, dt: 0.125000, bias: -4.664e-02, abs_bias: 4.664e-02 ± 4.631e-02\n",
      "Steps:  16, dt: 0.062500, bias: -7.265e-03, abs_bias: 7.265e-03 ± 4.637e-02\n",
      "Steps:  32, dt: 0.031250, bias: -4.522e-02, abs_bias: 4.522e-02 ± 4.623e-02\n",
      "Steps:  64, dt: 0.015625, bias: -3.702e-02, abs_bias: 3.702e-02 ± 4.644e-02\n",
      " rk weak order estimate: 0.592\n",
      "\n",
      "Final  rk weak order estimate: 0.592\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f09f4d9943e802b8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
