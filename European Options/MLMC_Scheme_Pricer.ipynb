{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import erf, exp, log, sqrt\n",
    "import csv\n",
    "\n",
    "\n",
    "def N(x: float) -> float:\n",
    "    \"\"\"\n",
    "    Computes the CDF for the standard normal distribution\n",
    "\n",
    "    :param x: Value to evaluate the CDF\n",
    "    :return: The value of the cdf\n",
    "    \"\"\"\n",
    "    return 0.5 * (1.0 + erf(x / sqrt(2.0)))\n",
    "\n",
    "def bs_price_call(S0: float, K: float, r: float, sigma: float, T: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the analytical price of a European call option using the Black-Scholes formula.\n",
    "\n",
    "    :param S0: Initial stock price at t=0\n",
    "    :param K: Strike price\n",
    "    :param r: Risk free Rate\n",
    "    :param sigma: Volatility\n",
    "    :param T: Time to maturity in years\n",
    "    :return: Price of european option\n",
    "    \"\"\"\n",
    "    # Handle zero division issue\n",
    "\n",
    "    if T <= 0 or sigma <= 0:\n",
    "        return max(S0 - K, 0.0) * exp(-r * T)\n",
    "    vol = sigma * sqrt(T)\n",
    "    d1 = (log(S0 / K) + (r + 0.5 * sigma**2) * T) / vol\n",
    "    d2 = d1 - vol\n",
    "\n",
    "    # Return price\n",
    "    return S0 * N(d1) - K * exp(-r * T) * N(d2)\n",
    "\n",
    "\n",
    "def payoff_call(S_t: np.ndarray, K: float):\n",
    "    \"\"\"\n",
    "    Calculates the final payoff of a European Call Option\n",
    "\n",
    "    :param S_t: Stock price at t=0\n",
    "    :param K: Strike price\n",
    "    :return: Final payoff array\n",
    "    \"\"\"\n",
    "    return np.maximum(S_t - K, 0.0)\n",
    "\n",
    "\n",
    "def euler_step_to_maturity(S0: float, dW: np.ndarray, dt: float, r: float, sigma: float):\n",
    "    \"\"\"\n",
    "    Simulates asset price paths to maturity using the Euler Scheme\n",
    "\n",
    "    :param S0: Initial stock price at t=0\n",
    "    :param dW: Stock price at t=0\n",
    "    :param dt: Time to maturity in years\n",
    "    :param r: Risk free rate\n",
    "    :param sigma: Volatility\n",
    "\n",
    "    \"\"\"\n",
    "    s = np.full(dW.shape[0], S0, dtype=float)\n",
    "    for j in range(dW.shape[1]):\n",
    "        s += r * s * dt + sigma * s * dW[:, j]\n",
    "    return np.maximum(s, 0.0)\n",
    "\n",
    "def milstein_step_to_maturity(S0: float, dW: np.ndarray, dt: float, r: float, sigma: float):\n",
    "    \"\"\"\n",
    "    Simulates asset price paths to maturity using the Milstein Scheme\n",
    "\n",
    "    :param S0: Initial stock price at t=0\n",
    "    :param dW: Stock price at t=0\n",
    "    :param dt: Time to maturity in years\n",
    "    :param r: Risk free rate\n",
    "    :param sigma: Volatility\n",
    "    :return: A 1D array of simulated stock prices at maturity\n",
    "\n",
    "    \"\"\"\n",
    "    s = np.full(dW.shape[0], S0, dtype=float)\n",
    "    for j in range(dW.shape[1]):\n",
    "        s += r * s * dt + sigma * s * dW[:, j] + 0.5 * (sigma**2) * s * (dW[:, j]**2 - dt)\n",
    "    return np.maximum(s, 0.0)\n",
    "\n",
    "def rk_step_to_maturity(S0: float, dW: np.ndarray, dt: float, r: float, sigma: float):\n",
    "    \"\"\"\n",
    "    Simulates asset price paths to maturity using a Runge-Kutta Scheme\n",
    "\n",
    "    :param S0: Initial stock price at t=0\n",
    "    :param dW: Stock price at t=0\n",
    "    :param dt: Time to maturity in years\n",
    "    :param r: Risk free rate\n",
    "    :param sigma: Volatility\n",
    "    :return: A 1D array of simulated stock prices at maturity\n",
    "    \"\"\"\n",
    "    s = np.full(dW.shape[0], S0, dtype=float)\n",
    "    for j in range(dW.shape[1]):\n",
    "        # Predictor step using a full Milstein step for higher accuracy.\n",
    "        s_pred = s + r * s * dt + sigma * s * dW[:, j] + 0.5 * (sigma**2) * s * (dW[:, j]**2 - dt)\n",
    "        # Corrector step (averaging the drift term).\n",
    "        s = s + 0.5 * (r * s + r * s_pred) * dt + sigma * s * dW[:, j] + 0.5 * (sigma**2) * s * (dW[:, j]**2 - dt)\n",
    "    return np.maximum(s, 0.0)\n",
    "\n",
    "\n",
    "def weak_order_convergence(path_simulator, S0:float, K:float, r:float, sigma:float, T:float, exact_price:float, Npaths:float=200000, seed=332093):\n",
    "    \"\"\"\n",
    "    Performs a weak order convergence analysis for a given scheme, printing bias vs time step size\n",
    "\n",
    "    :param path_simulator: SDE function to test\n",
    "    :param S0: Initial stock price at t=0\n",
    "    :param K: Strike price\n",
    "    :param r: Risk free rate\n",
    "    :param sigma: Volatility\n",
    "    :param T: Time to maturity in years\n",
    "    :param exact_price: Exact price\n",
    "    :param Npaths: Number of paths to simulate at each resolution\n",
    "    :param seed: Random seed\n",
    "    :return: Converegence results and estimated weak order\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    results = []\n",
    "\n",
    "    # Use time step progression for loop\n",
    "    steps_list = [2**i for i in range(12)]\n",
    "\n",
    "    for n in steps_list:\n",
    "        dt = T / n\n",
    "        dW = rng.normal(0.0, sqrt(dt), size=(Npaths, n))\n",
    "        S_approx = path_simulator(S0, dW, dt, r, sigma)\n",
    "        P_approx = exp(-r * T) * payoff_call(S_approx, K)\n",
    "\n",
    "        mean_approx = np.mean(P_approx)\n",
    "        bias = mean_approx - exact_price\n",
    "        se_mean = np.std(P_approx, ddof=1) / np.sqrt(Npaths)\n",
    "\n",
    "        results.append({'dt': dt, 'abs_bias': abs(bias), 'se': se_mean})\n",
    "        print(f\"Steps: {n:3d}, dt: {dt:.6f}, bias: {bias:+.3e}, abs_bias: {abs(bias):.3e} ± {se_mean:.3e}\")\n",
    "\n",
    "    # Fit convergence rate using points where bias is statistically significant\n",
    "    dts = np.array([r['dt'] for r in results])\n",
    "    abs_biases = np.array([r['abs_bias'] for r in results])\n",
    "    se_biases = np.array([r['se'] for r in results])\n",
    "\n",
    "    # Mask noisy point where bias is too small\n",
    "    mask = abs_biases > 2.0 * se_biases\n",
    "    if np.sum(mask) >= 2:\n",
    "        log_dts = np.log(dts[mask])\n",
    "        log_biases = np.log(abs_biases[mask])\n",
    "        # Linear Regression on log log plot to get slope/convergence rate\n",
    "        alpha, _ = np.polyfit(log_dts, log_biases, 1)\n",
    "        weak_order = alpha\n",
    "        print(f\"Weak order estimate: {weak_order:.3f}\")\n",
    "    else:\n",
    "        # Fallback if not enough data point due to insignificance of points\n",
    "        weak_order = 1.0\n",
    "        print(\"Using theoretical weak order = 1.0\")\n",
    "\n",
    "    return results, weak_order\n",
    "\n",
    "\n",
    "def mlmc_adaptive(path_simulator, S0: float, K: float, r: float, sigma: float, T: float, M: int, eps: float, seed: int = 42221):\n",
    "    \"\"\"\n",
    "    This function implements an adaptive MLMC algorithm that automatically determines the number of levels and samples needed to achieve a target accuracy\n",
    "\n",
    "    :param path_simulator: SDE function to test\n",
    "    :param S0: Initial stock price at t=0\n",
    "    :param K: Strike price\n",
    "    :param r: Risk free rate\n",
    "    :param sigma: Volatility\n",
    "    :param T: Time to maturity in years\n",
    "    :param M: Number of levels\n",
    "    :param eps: RMSE tolerance\n",
    "    :param seed: Random seed\n",
    "    :return: MLMC results incl price,SE and level diagnostics\n",
    "\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    L, L_max, N0 = 2, 8, 2000\n",
    "\n",
    "    # Initialise arrays to store per-level statistics\n",
    "    means, variances, Nl, costs = [np.zeros(L_max + 1) for _ in range(4)]\n",
    "\n",
    "    #TODO: Typecast fixes for now\n",
    "    Nl = Nl.astype(int)\n",
    "\n",
    "    # Initial sampling for the first few levels to get first estimates of stats\n",
    "    for l in range(L + 1):\n",
    "        Nl[l] = max(100, N0 // (M ** l))\n",
    "        Y, cost_per_sample = mlmc_sample_level(path_simulator, S0, K, r, sigma, T, l, Nl[l], rng, M)\n",
    "        means[l] = np.mean(Y)\n",
    "        variances[l] = np.var(Y, ddof=1)\n",
    "        costs[l] = cost_per_sample\n",
    "        print(f\"Level {l}: N={Nl[l]}, mean={means[l]:+.4e}, var={variances[l]:.2e}\")\n",
    "\n",
    "    # Iteratively add levels and samples until the MSE target is met\n",
    "    for iteration in range(15):\n",
    "        # Check if we need more levels (bias check)\n",
    "        if L < L_max and abs(means[L]) > eps / sqrt(2):\n",
    "            L += 1\n",
    "            Nl[L] = max(100, N0 // (M ** L))\n",
    "            Y, cost_per_sample = mlmc_sample_level(path_simulator, S0, K, r, sigma, T, L, Nl[L], rng, M)\n",
    "            means[L], variances[L], costs[L] = np.mean(Y), np.var(Y, ddof=1), cost_per_sample\n",
    "            print(f\"Added level {L}: N={Nl[L]}, mean={means[L]:+.4e}, var={variances[L]:.2e}\")\n",
    "            continue\n",
    "\n",
    "        # Check if the desired accuracy (variance check) has been met\n",
    "        total_var = sum(variances[l] / max(Nl[l], 1) for l in range(L + 1))\n",
    "        if total_var < eps**2:\n",
    "            print(f\"Converged: total variance {total_var:.3e} < target {eps**2:.3e}\")\n",
    "            break\n",
    "\n",
    "        # Calculate optimal sample allocation\n",
    "        N_opt = np.zeros(L + 1)\n",
    "        for l in range(L + 1):\n",
    "            if variances[l] > 0 and costs[l] > 0:\n",
    "                N_opt[l] = max(100, int(np.sqrt(variances[l] / costs[l]) *\n",
    "                                 sum(np.sqrt(variances[:L+1] * costs[:L+1])) / eps**2))\n",
    "\n",
    "        # Generate additional samples to meet the new optimal allocation\n",
    "        samples_added = 0\n",
    "        for l in range(L + 1):\n",
    "            extra = max(0, int(N_opt[l] - Nl[l]))\n",
    "            if extra > 0:\n",
    "                Y_extra, _ = mlmc_sample_level(path_simulator, S0, K, r, sigma, T, l, extra, rng, M)\n",
    "                # Update mean and variance with new samples\n",
    "                total_samples = Nl[l] + extra\n",
    "                combined_mean = (Nl[l] * means[l] + np.sum(Y_extra)) / total_samples\n",
    "                if Nl[l] > 1 and extra > 1:\n",
    "                    var_extra = np.var(Y_extra, ddof=1)\n",
    "                    variances[l] = ((Nl[l] - 1) * variances[l] + (extra - 1) * var_extra +\n",
    "                                  Nl[l] * (means[l] - combined_mean)**2 +\n",
    "                                  extra * (np.mean(Y_extra) - combined_mean)**2) / (total_samples - 1)\n",
    "                means[l] = combined_mean\n",
    "                Nl[l] += extra\n",
    "                samples_added += extra\n",
    "                print(f\"Level {l}: added {extra} samples, new N={Nl[l]}, mean={means[l]:+.4e}\")\n",
    "\n",
    "        if samples_added == 0:\n",
    "            print(\"No additional samples needed - convergence achieved\")\n",
    "            break\n",
    "\n",
    "    # Summation of values provide price,se and total cost\n",
    "    price = sum(means[:L+1])\n",
    "    se = sqrt(sum(variances[l] / max(Nl[l], 1) for l in range(L + 1)))\n",
    "    total_cost = sum(Nl[l] * costs[l] for l in range(L + 1))\n",
    "\n",
    "    return {'price': price, 'se': se, 'L': L, 'Nl': Nl[:L+1], 'means': means[:L+1], 'vars': variances[:L+1], 'cost': total_cost}\n",
    "\n",
    "def mlmc_non_adaptive(path_simulator, S0: float, K: float, r: float, sigma: float, T: float, L_max: int, M: int, eps: float, N0: int = 1000, seed: int = 42221):\n",
    "    \"\"\"\n",
    "    Implements a non-adaptive MLMC algorithm with a fixed number of levels, allocating\n",
    "    samples based on variance and cost estimates.\n",
    "\n",
    "    :param path_simulator: The SDE function to test (e.g., euler_step_to_maturity).\n",
    "    :param S0: Initial stock price.\n",
    "    :param K: Strike price.\n",
    "    :param r: Risk-free rate.\n",
    "    :param sigma: Volatility.\n",
    "    :param T: Time to maturity.\n",
    "    :param L_max: Maximum number of levels (L=0 to L_max).\n",
    "    :param M: Refinement factor.\n",
    "    :param eps: Target RMSE tolerance.\n",
    "    :param N0: Initial number of samples for the estimation phase.\n",
    "    :param seed: Random seed.\n",
    "    :return: A dictionary of MLMC results.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # Initial sampling to estimate variances and costs\n",
    "    means = np.zeros(L_max + 1)\n",
    "    variances = np.zeros(L_max + 1)\n",
    "    costs = np.zeros(L_max + 1)\n",
    "\n",
    "    print(\"--- Initial Sampling to Estimate Variances and Costs ---\")\n",
    "    for l in range(L_max + 1):\n",
    "        Y, cost_per_sample = mlmc_sample_level(path_simulator, S0, K, r, sigma, T, l, N0, rng, M)\n",
    "        means[l] = np.mean(Y)\n",
    "        variances[l] = np.var(Y, ddof=1)\n",
    "        costs[l] = cost_per_sample\n",
    "        print(f\"Level {l}: Est. Var = {variances[l]:.3e}, Est. Cost = {costs[l]:.0f}\")\n",
    "\n",
    "    # Calculate optimal sample allocation\n",
    "    sqrt_cost = np.sqrt(costs)\n",
    "    sqrt_var_div_cost = np.sqrt(variances / costs)\n",
    "\n",
    "    # Calculate the total computational cost C for the target RMSE epsilon\n",
    "    C = (sum(sqrt_var_div_cost) * sum(np.sqrt(variances) * sqrt_cost)) / eps**2\n",
    "    Nl_opt = np.zeros(L_max + 1, dtype=int)\n",
    "    for l in range(L_max + 1):\n",
    "        Nl_opt[l] = max(100, int(C * sqrt_var_div_cost[l] / sum(sqrt_var_div_cost)))\n",
    "\n",
    "    print(\"\\n--- Optimal Sample Allocation ---\")\n",
    "    print(f\"Optimal samples per level: {Nl_opt}\")\n",
    "\n",
    "    final_means = np.zeros(L_max + 1)\n",
    "    final_variances = np.zeros(L_max + 1)\n",
    "    total_cost = 0\n",
    "\n",
    "    for l in range(L_max + 1):\n",
    "        Y, cost_per_sample = mlmc_sample_level(path_simulator, S0, K, r, sigma, T, l, Nl_opt[l], rng, M)\n",
    "        final_means[l] = np.mean(Y)\n",
    "        final_variances[l] = np.var(Y, ddof=1)\n",
    "        total_cost += Nl_opt[l] * cost_per_sample\n",
    "        print(f\"Level {l}: N={Nl_opt[l]}, Mean = {final_means[l]:+.4e}\")\n",
    "\n",
    "    # Final calculation of price and standard error\n",
    "    price = sum(final_means)\n",
    "    se = sqrt(sum(final_variances[l] / Nl_opt[l] for l in range(L_max + 1)))\n",
    "\n",
    "    return {'price': price, 'se': se, 'L': L_max, 'Nl': Nl_opt, 'means': final_means, 'vars': final_variances, 'cost': total_cost}\n",
    "\n",
    "\n",
    "def mlmc_sample_level(path_simulator, S0:float, K:float, r:float, sigma:float, T:float, l:float, N_l:float, rng:float, M:float):\n",
    "    \"\"\"\n",
    "    Generates samples for a single MLMC level and returns the cost\n",
    "\n",
    "    :param path_simulator: SDE function to test\n",
    "    :param S0: initial price\n",
    "    :param K: number of samples\n",
    "    :param r: risk-free interest rate\n",
    "    :param sigma: volatility\n",
    "    :param T: time to maturity\n",
    "    :param l: level\n",
    "    :param N_l: number of samples to generate for this level\n",
    "    :param rng: random number generator\n",
    "    :param M: Refinement factor\n",
    "\n",
    "    :returns: Tuple of generated samples and cost per sample\n",
    "\n",
    "    \"\"\"\n",
    "    n_fine = M**l\n",
    "    dt_f = T / n_fine\n",
    "    cost = n_fine\n",
    "\n",
    "    # Generate a single set of random increments for the finest grid.\n",
    "    dW_f = rng.normal(0.0, sqrt(dt_f), size=(N_l, n_fine))\n",
    "\n",
    "    if l == 0:\n",
    "        Sf = path_simulator(S0, dW_f, dt_f, r, sigma)\n",
    "        Y = exp(-r * T) * payoff_call(Sf, K)\n",
    "    else:\n",
    "        # Generate increments of coarse by summing fine path increments\n",
    "        dW_c = dW_f.reshape(N_l, n_fine // M, M).sum(axis=2)\n",
    "        dt_c = T / (n_fine // M)\n",
    "        Sf = path_simulator(S0, dW_f, dt_f, r, sigma)\n",
    "        Sc = path_simulator(S0, dW_c, dt_c, r, sigma)\n",
    "        Y = exp(-r * T) * (payoff_call(Sf, K) - payoff_call(Sc, K))\n",
    "    return Y, cost\n",
    "\n",
    "def plot_combined_weak_convergence(results_dict):\n",
    "    \"\"\"Plots the weak convergence results for all schemes on a single log-log plot\n",
    "\n",
    "    :param results_dict: Dictionary where keys are schme names and values are list of dict containing conv data\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for name, results_list in results_dict.items():\n",
    "        dts = np.array([r['dt'] for r in results_list])\n",
    "        abs_biases = np.array([r['abs_bias'] for r in results_list])\n",
    "        plt.loglog(dts, abs_biases, 'o-', label=f'{name} Scheme', linewidth=2, markersize=8)\n",
    "\n",
    "    # Use the first scheme's dt for reference line scaling\n",
    "    first_key = list(results_dict.keys())[0]\n",
    "    ref_dt = np.array([results_dict[first_key][0]['dt'], results_dict[first_key][-1]['dt']])\n",
    "\n",
    "    plt.loglog(ref_dt, 0.1 * ref_dt, 'k--', label='Reference O($\\Delta$t)', alpha=0.7)\n",
    "    plt.loglog(ref_dt, 0.01 * ref_dt**1.5, 'k:', label='Reference O($\\Delta$t$^{1.5}$)', alpha=0.7)\n",
    "\n",
    "    plt.xlabel('Time Step Size ($\\Delta$t)', fontsize=14)\n",
    "    plt.ylabel('Absolute Bias |Error|', fontsize=14)\n",
    "    plt.title('Weak Convergence Comparison', fontsize=16)\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    S0, K, r, sigma, T = 1, 1, 0.05, 0.20, 1.0\n",
    "    M = 4\n",
    "    exact_price = bs_price_call(S0, K, r, sigma, T)\n",
    "    print(f\"Black–Scholes call price: {exact_price:.6f}\\n\")\n",
    "\n",
    "    schemes = {\n",
    "        \"Euler\": euler_step_to_maturity,\n",
    "        \"Milstein\": milstein_step_to_maturity,\n",
    "        \"SRK\": rk_step_to_maturity\n",
    "    }\n",
    "\n",
    "    # Weak Order Convergence Analysis\n",
    "    print(\"=== Weak Order Convergence Analysis ===\")\n",
    "    weak_results_all = {}\n",
    "    weak_orders = {}\n",
    "    for name, simulator in schemes.items():\n",
    "        print(f\"\\n--- Analysing {name} Scheme ---\")\n",
    "        results, order = weak_order_convergence(simulator, S0, K, r, sigma, T, exact_price, seed=21541254)\n",
    "        weak_results_all[name] = results\n",
    "        weak_orders[name] = order\n",
    "\n",
    "        # Save weak convergence data for this scheme\n",
    "        conv_filename = f\"{name.lower()}_weak_convergence.dat\"\n",
    "        with open(conv_filename, 'w', newline='') as f:\n",
    "            writer = csv.writer(f, delimiter=' ')\n",
    "            writer.writerow(['dt', 'abs_bias'])\n",
    "            for res in results:\n",
    "                writer.writerow([res['dt'], res['abs_bias']])\n",
    "        print(f\"Saved weak convergence data to '{conv_filename}'\")\n",
    "\n",
    "    print(f\"\\n=== Weak Order Summary ===\")\n",
    "    for name, order in weak_orders.items():\n",
    "        print(f\"{name} weak order: {order:.3f}\")\n",
    "\n",
    "    plot_combined_weak_convergence(weak_results_all)\n",
    "\n",
    "    # MLMC Analysis (Non-Adaptive and Adaptive)\n",
    "    print(\"\\n\\n=== MLMC Analysis ===\")\n",
    "    # Initialise the results dictionary ONCE\n",
    "    mlmc_results_all = {}\n",
    "\n",
    "    # A single, clean loop for all MLMC analysis\n",
    "    for name, simulator in schemes.items():\n",
    "        print(f\"\\n--- Running MLMC for {name} Scheme ---\")\n",
    "\n",
    "        # Run Non-Adaptive MLMC\n",
    "        print(\"\\n--- Non-Adaptive MLMC ---\")\n",
    "        non_adaptive_results = mlmc_non_adaptive(simulator, S0, K, r, sigma, T, L_max=8, M=M, eps=0.001)\n",
    "\n",
    "        # Run Adaptive MLMC\n",
    "        print(\"\\n--- Adaptive MLMC ---\")\n",
    "        adaptive_results = mlmc_adaptive(simulator, S0, K, r, sigma, T, M=M, eps=0.001)\n",
    "\n",
    "        # Store BOTH results in the correct nested structure\n",
    "        mlmc_results_all[name] = {\n",
    "            'nonadaptive': non_adaptive_results,\n",
    "            'adaptive': adaptive_results\n",
    "        }\n",
    "\n",
    "        # Save MLMC diagnostics data for the adaptive run\n",
    "        diag_filename = f\"{name.lower()}_mlmc_diagnostics.dat\"\n",
    "        with open(diag_filename, 'w', newline='') as f:\n",
    "            writer = csv.writer(f, delimiter=' ')\n",
    "            writer.writerow(['l', 'logM_var', 'logM_abs_mean', 'Nl'])\n",
    "            for l_val in range(adaptive_results['L'] + 1):\n",
    "                # Add a small epsilon to avoid log(0)\n",
    "                logM_var = np.log(adaptive_results['vars'][l_val] + 1e-12) / np.log(M)\n",
    "                logM_abs_mean = np.log(abs(adaptive_results['means'][l_val]) + 1e-12) / np.log(M)\n",
    "                writer.writerow([l_val, logM_var, logM_abs_mean, adaptive_results['Nl'][l_val]])\n",
    "        print(f\"Saved MLMC diagnostics data to '{diag_filename}'\")\n",
    "\n",
    "    # Final Summary of MLMC results\n",
    "    print(f\"\\n\\n=== Final MLMC Results Summary ===\")\n",
    "    print(f\"Exact price: {exact_price:.6f}\")\n",
    "    for name, results in mlmc_results_all.items():\n",
    "        print(f\"\\n--- {name} Scheme ---\")\n",
    "        std_res = results['nonadaptive']\n",
    "        adt_res = results['adaptive']\n",
    "        std_norm_err = abs(std_res['price'] - exact_price) / exact_price\n",
    "        adt_norm_err = abs(adt_res['price'] - exact_price) / exact_price\n",
    "\n",
    "        print(f\"Non Adaptive: Price={std_res['price']:.6f} ± {std_res['se']:.6f}, Cost={std_res['cost']:.0f}, NormErr={std_norm_err:.4f}\")\n",
    "        print(f\"Adaptive: Price={adt_res['price']:.6f} ± {adt_res['se']:.6f}, Cost={adt_res['cost']:.0f}, NormErr={adt_norm_err:.4f}\")\n"
   ],
   "id": "4b7526a4664bcb10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e4511c386cdb7476"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
